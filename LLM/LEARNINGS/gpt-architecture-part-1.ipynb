{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install tiktoken","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:08:07.881420Z","iopub.execute_input":"2024-12-01T21:08:07.881850Z","iopub.status.idle":"2024-12-01T21:08:17.850655Z","shell.execute_reply.started":"2024-12-01T21:08:07.881813Z","shell.execute_reply":"2024-12-01T21:08:17.849328Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tiktoken in /opt/conda/lib/python3.10/site-packages (0.8.0)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2024.5.15)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"GPT_CONFIG_124M = {\n    \"vocab_size\": 50257,    # Vocabulary size\n    \"context_length\": 1024, # Context length\n    \"emb_dim\": 768,         # Embedding dimension\n    \"n_heads\": 12,          # Number of attention heads\n    \"n_layers\": 12,         # Number of layers\n    \"drop_rate\": 0.1,       # Dropout rate\n    \"qkv_bias\": False       # Query-Key-Value bias\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:08:17.853579Z","iopub.execute_input":"2024-12-01T21:08:17.854133Z","iopub.status.idle":"2024-12-01T21:08:17.860697Z","shell.execute_reply.started":"2024-12-01T21:08:17.854079Z","shell.execute_reply":"2024-12-01T21:08:17.859483Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n\nclass DummyGPTModel(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n        \n        # Use a placeholder for TransformerBlock\n        self.trf_blocks = nn.Sequential(\n            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n        \n        # Use a placeholder for LayerNorm\n        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n        self.out_head = nn.Linear(\n            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n        )\n\n    def forward(self, in_idx):\n        batch_size, seq_len = in_idx.shape\n        tok_embeds = self.tok_emb(in_idx)\n        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n        x = tok_embeds + pos_embeds\n        x = self.drop_emb(x)\n        x = self.trf_blocks(x)\n        x = self.final_norm(x)\n        logits = self.out_head(x)\n        return logits\n\n\nclass DummyTransformerBlock(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        # A simple placeholder\n\n    def forward(self, x):\n        # This block does nothing and just returns its input.\n        return x\n\n\nclass DummyLayerNorm(nn.Module):\n    def __init__(self, normalized_shape, eps=1e-5):\n        super().__init__()\n        # The parameters here are just to mimic the LayerNorm interface.\n\n    def forward(self, x):\n        # This layer does nothing and just returns its input.\n        return x","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:08:17.861946Z","iopub.execute_input":"2024-12-01T21:08:17.862295Z","iopub.status.idle":"2024-12-01T21:08:17.879798Z","shell.execute_reply.started":"2024-12-01T21:08:17.862257Z","shell.execute_reply":"2024-12-01T21:08:17.878623Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import tiktoken\ntokenizer = tiktoken.get_encoding(\"gpt2\")\nbatch = []\ntxt1 = \"Every effort moves you\"\ntxt2 = \"Every day holds a\"\nbatch.append(torch.tensor(tokenizer.encode(txt1)))\nbatch.append(torch.tensor(tokenizer.encode(txt2)))\nbatch = torch.stack(batch, dim=0)\nprint(batch)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:08:17.881455Z","iopub.execute_input":"2024-12-01T21:08:17.882464Z","iopub.status.idle":"2024-12-01T21:08:19.479037Z","shell.execute_reply.started":"2024-12-01T21:08:17.882410Z","shell.execute_reply":"2024-12-01T21:08:19.477879Z"}},"outputs":[{"name":"stdout","text":"tensor([[6109, 3626, 6100,  345],\n        [6109, 1110, 6622,  257]])\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"torch.manual_seed(123)\nmodel = DummyGPTModel(GPT_CONFIG_124M)\nlogits = model(batch)\nprint(\"Output shape:\", logits.shape)\nprint(logits)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:08:19.481013Z","iopub.execute_input":"2024-12-01T21:08:19.481363Z","iopub.status.idle":"2024-12-01T21:08:20.418216Z","shell.execute_reply.started":"2024-12-01T21:08:19.481329Z","shell.execute_reply":"2024-12-01T21:08:20.417084Z"}},"outputs":[{"name":"stdout","text":"Output shape: torch.Size([2, 4, 50257])\ntensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n         [-0.4476,  0.1726,  0.5354,  ..., -0.3932,  1.5285,  0.8557],\n         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n         [ 0.0447,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n\n        [[-1.5474, -0.0542, -1.0571,  ..., -1.8061, -0.4494, -0.6747],\n         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n       grad_fn=<UnsafeViewBackward0>)\n","output_type":"stream"}],"execution_count":14}]}