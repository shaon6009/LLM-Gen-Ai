{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9sQWetuDvkGo"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install langchain langchain_core langchain_groq langchain_community langgraph gradio\n",
        "!pip install gradio pandas uuid chromadb langchain langchain-community langchain-core pymupdf openai-whisper\n",
        "!pip install gTTS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import fitz  # PyMuPDF\n",
        "import mimetypes\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_groq import ChatGroq\n",
        "from gtts import gTTS\n",
        "#import pyttsx3 for run it in locally\n",
        "import os\n",
        "import uuid"
      ],
      "metadata": {
        "id": "VsoogD37vmcX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(\n",
        "    temperature=0,\n",
        "    groq_api_key=\"Your api\",\n",
        "    model_name=\"llama-3.3-70b-versatile\"\n",
        ")"
      ],
      "metadata": {
        "id": "oLh2D0f2vmeu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cv_text(cv_file):\n",
        "    file_type, _ = mimetypes.guess_type(cv_file.name)\n",
        "    if file_type == 'application/pdf':\n",
        "        try:\n",
        "            doc = fitz.open(cv_file.name)\n",
        "            text = \"\\n\".join(page.get_text() for page in doc)\n",
        "            doc.close()\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            return f\"Failed to read PDF: {e}\"\n",
        "    else:\n",
        "        try:\n",
        "            return cv_file.read().decode(\"utf-8\")\n",
        "        except Exception:\n",
        "            return \"Unsupported file format or decoding failed.\"\n",
        "\n",
        "def analyze_cv_against_job(cv_text, job_text):\n",
        "    # Detailed, friendly prompt for the LLM\n",
        "    prompt = PromptTemplate.from_template(\"\"\"\n",
        "Hey! You're a super friendly and helpful CV coach.\n",
        "\n",
        "Please compare the CV below with the job description and give me:\n",
        "\n",
        "1. A score out of 100 that shows how well the CV fits the job.\n",
        "2. Very detailed, easy-to-understand, and casual feedback on what could be improved.\n",
        "   - Break down feedback clearly by areas like skills, experience, formatting, or anything missing.\n",
        "   - Explain every fault or gap in a positive and encouraging way, so the candidate feels motivated to improve.\n",
        "   - Use simple language that anyone can understand.\n",
        "3. If the CV is great (score 85+), also add a warm \"Good job! Your CV looks solid.\"\n",
        "\n",
        "Return the result strictly as JSON:\n",
        "\n",
        "{{\n",
        "  \"score\": int,\n",
        "  \"feedback\": string\n",
        "}}\n",
        "\n",
        "### CV:\n",
        "{cv}\n",
        "\n",
        "### JOB DESCRIPTION:\n",
        "{job}\n",
        "\"\"\")\n",
        "\n",
        "    parser = JsonOutputParser()\n",
        "    chain = prompt | llm | RunnableLambda(lambda x: x.content.strip())\n",
        "\n",
        "    try:\n",
        "        raw = chain.invoke({\"cv\": cv_text, \"job\": job_text})\n",
        "        result = parser.parse(raw)\n",
        "        return result[\"score\"], result[\"feedback\"]\n",
        "    except Exception as e:\n",
        "        return 0, f\"Oops, something went wrong: {e}\"\n",
        "\n",
        "def text_to_speech(feedback, voice_gender):\n",
        "    lang_code = \"en-IN\"\n",
        "\n",
        "\n",
        "    tld = \"com\" if voice_gender == \"Man\" else \"co.in\"\n",
        "\n",
        "    try:\n",
        "        tts = gTTS(text=feedback, lang=lang_code, tld=tld)\n",
        "        path = f\"/tmp/feedback_{uuid.uuid4().hex}.mp3\"\n",
        "        tts.save(path)\n",
        "        return path\n",
        "    except Exception as e:\n",
        "        print(\"Speech generation failed:\", e)\n",
        "        return None\n",
        "\n",
        "def main(cv_file, job_text_or_url, voice_gender):\n",
        "    cv_text = load_cv_text(cv_file)\n",
        "    if job_text_or_url.startswith(\"http\"):\n",
        "        loader = WebBaseLoader(job_text_or_url)\n",
        "        job_text = loader.load().pop().page_content\n",
        "    else:\n",
        "        job_text = job_text_or_url\n",
        "\n",
        "    score, feedback = analyze_cv_against_job(cv_text, job_text)\n",
        "    audio = text_to_speech(feedback, voice_gender)\n",
        "    report = f\"Score: {score}/100\\n\\nFeedback:\\n{feedback}\"\n",
        "    return report, audio\n",
        "\n",
        "ui = gr.Interface(\n",
        "    fn=main,\n",
        "    inputs=[\n",
        "        gr.File(label=\"Upload CV (PDF or TXT)\"),\n",
        "        gr.Textbox(label=\"Job Description or URL\", lines=10, placeholder=\"Paste job description text or URL here\"),\n",
        "        gr.Radio([\"Voice1\", \"Voice2\"], label=\"Select Voice for Speech Feedback\", value=\"Woman\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Feedback Report\"),\n",
        "        gr.Audio(label=\"Speech Feedback\", type=\"filepath\")\n",
        "    ],\n",
        "    title=\"CV Analyzer & Friendly Feedback Generator\",\n",
        "    description=\"Upload your CV and job description. Get scored feedback and friendly, detailed improvement tips with selectable voices.\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "ui.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "mICGcLQVvmjP",
        "outputId": "daea4860-0ee5-4e21-c2c3-b4d5d8faeff5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3a930a927fdf8ea011.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3a930a927fdf8ea011.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vx22YjdKvmln"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}