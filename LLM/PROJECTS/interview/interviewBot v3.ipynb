{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "510d86b59d674b1ca567abba4876b096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5828ddc0ae2c44659b25b4f5978958bd",
              "IPY_MODEL_b73f046b8ccc42659f4c87ab057f1ad2",
              "IPY_MODEL_86fa16489f1745199ebd7f18475014a5"
            ],
            "layout": "IPY_MODEL_5f767251b0e145deac9123111e61ab37"
          }
        },
        "5828ddc0ae2c44659b25b4f5978958bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fea7aea11b45449e85bf030175c5e1d8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1a0d77ba0bc3451f8133e9de7b6c5ae3",
            "value": "theme_schema%401.2.1.json:â€‡100%"
          }
        },
        "b73f046b8ccc42659f4c87ab057f1ad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b700d3f7aee4b949126ad1c72e84367",
            "max": 14459,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93697327ca0c47138fe4c31c5a6b42cb",
            "value": 14459
          }
        },
        "86fa16489f1745199ebd7f18475014a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ca9571144d94a5a844b3f323974656d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_971b575132d348ebbb3c16a6c042bb71",
            "value": "â€‡14.5k/14.5kâ€‡[00:00&lt;00:00,â€‡761kB/s]"
          }
        },
        "5f767251b0e145deac9123111e61ab37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fea7aea11b45449e85bf030175c5e1d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a0d77ba0bc3451f8133e9de7b6c5ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b700d3f7aee4b949126ad1c72e84367": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93697327ca0c47138fe4c31c5a6b42cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ca9571144d94a5a844b3f323974656d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "971b575132d348ebbb3c16a6c042bb71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install langchain langchain_core langchain_groq langchain_community langgraph gradio\n",
        "!pip install gradio pandas uuid chromadb langchain langchain-community langchain-core pymupdf openai-whisper"
      ],
      "metadata": {
        "id": "CJDt8ZCC5JSN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ZFR8IXQSReF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import uuid\n",
        "import random\n",
        "import chromadb\n",
        "import datetime\n",
        "import fitz  # PyMuPDF for PDF reading\n",
        "import mimetypes\n",
        "import whisper\n",
        "import re\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "# -------------------- LLM Setup --------------------\n",
        "llm = ChatGroq(\n",
        "    temperature=0,\n",
        "    groq_api_key=\"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\",\n",
        "    model_name=\"llama-3.3-70b-versatile\"\n",
        ")\n",
        "\n",
        "model_whisper = whisper.load_model(\"base\")\n",
        "\n",
        "# -------------------- Question Bank --------------------\n",
        "question_bank = {\n",
        "    \"General & Motivational\": [\n",
        "        \"Why do you want to join this company?\",\n",
        "        \"What motivates you to come to work every day?\",\n",
        "        \"What makes you different from others?\",\n",
        "        \"Where do you see yourself in 5 years?\",\n",
        "        \"Why should we hire you?\"\n",
        "    ],\n",
        "    \"Situational & Skill-Based\": [\n",
        "        \"Describe a time you handled failure.\",\n",
        "        \"Tell me about a tight deadline situation.\",\n",
        "        \"Describe a challenge at work and how you overcame it.\",\n",
        "        \"Have you solved a problem without full info?\",\n",
        "        \"How do you deal with stress?\"\n",
        "    ],\n",
        "    \"Teamwork & Leadership\": [\n",
        "        \"How would teammates describe you?\",\n",
        "        \"Tell me about a team conflict you resolved.\",\n",
        "        \"Have you ever led a team? What was your approach?\",\n",
        "        \"How do you give/receive feedback?\"\n",
        "    ],\n",
        "    \"Work Style & Personality\": [\n",
        "        \"How do you stay organized?\",\n",
        "        \"What's your strength and weakness?\",\n",
        "        \"Do you prefer team or solo work?\",\n",
        "        \"How do you keep up with trends?\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# -------------------- Loaders --------------------\n",
        "def load_cv(cv_file=None, cv_url=None):\n",
        "    if cv_url:\n",
        "        loader = WebBaseLoader(cv_url)\n",
        "        return loader.load().pop().page_content\n",
        "    elif cv_file:\n",
        "        file_type, _ = mimetypes.guess_type(cv_file.name)\n",
        "        if file_type == 'application/pdf':\n",
        "            try:\n",
        "                doc = fitz.open(cv_file.name)\n",
        "                text = \"\\n\".join([page.get_text() for page in doc])\n",
        "                doc.close()\n",
        "                return text\n",
        "            except Exception as e:\n",
        "                return f\"Failed to read PDF: {str(e)}\"\n",
        "        else:\n",
        "            try:\n",
        "                return cv_file.read().decode(\"utf-8\")\n",
        "            except:\n",
        "                return \"Unsupported file format or decoding failed.\"\n",
        "    return \"\"\n",
        "\n",
        "def extract_job_info(job_text_or_url):\n",
        "    try:\n",
        "        if job_text_or_url.startswith(\"http\"):\n",
        "            loader = WebBaseLoader(job_text_or_url)\n",
        "            page_data = loader.load().pop().page_content\n",
        "        else:\n",
        "            page_data = job_text_or_url\n",
        "\n",
        "        parser = JsonOutputParser()\n",
        "\n",
        "        prompt = PromptTemplate.from_template(\"\"\"\n",
        "        You are a hiring analyst. Analyze the following job description text and return structured job details in JSON format.\n",
        "\n",
        "        ### INPUT:\n",
        "        {page_data}\n",
        "\n",
        "        ### OUTPUT FORMAT:\n",
        "        {format_instructions}\n",
        "        \"\"\").partial(format_instructions=parser.get_format_instructions())\n",
        "\n",
        "        chain = prompt | llm | RunnableLambda(lambda x: x.content.strip())\n",
        "        result = chain.invoke({'page_data': page_data})\n",
        "        return parser.parse(result)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"âš ï¸ Failed to extract job info:\", str(e))\n",
        "        return {\n",
        "            \"role\": \"Unknown\",\n",
        "            \"experience\": \"Not specified\",\n",
        "            \"skills\": [],\n",
        "            \"description\": page_data[:500] + \"...\"\n",
        "        }\n",
        "\n",
        "# -------------------- Interview Logic --------------------\n",
        "interview_data = []\n",
        "\n",
        "def ask_next_question(question, answer):\n",
        "    prompt = PromptTemplate.from_template(\"\"\"\n",
        "        ### QUESTION:\n",
        "        {question}\n",
        "\n",
        "        ### ANSWER:\n",
        "        {answer}\n",
        "\n",
        "        ### INSTRUCTION:\n",
        "        Evaluate the candidate's answer and score it from 0 to 100.\n",
        "\n",
        "        Then, based on the score, craft human-like, professional, and emotionally intelligent feedback:\n",
        "        - If the score is >= 85, give praise and note what stood out.\n",
        "        - If score is 70â€“84, mention it was solid and how to polish it further.\n",
        "        - If 50â€“69, highlight the potential and suggest key improvements.\n",
        "        - If below 50, be honest but empathetic, give constructive criticism, and encouragement.\n",
        "\n",
        "        Return this JSON format:\n",
        "        {{\n",
        "            \"score\": 78,\n",
        "            \"feedback\": \"Your answer was structured and thoughtful. With more specific examples, it could be excellent.\"\n",
        "        }}\n",
        "    \"\"\")\n",
        "\n",
        "    chain = prompt | llm | RunnableLambda(lambda x: x.content.strip())\n",
        "    raw_output = chain.invoke({\"question\": question, \"answer\": answer})\n",
        "\n",
        "    match = re.search(r\"\\{.*\\}\", raw_output, re.DOTALL)\n",
        "    if match:\n",
        "        json_part = match.group()\n",
        "        parser = JsonOutputParser()\n",
        "        return parser.parse(json_part)\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid response format: {raw_output}\")\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    try:\n",
        "        result = model_whisper.transcribe(audio_path)\n",
        "        return result[\"text\"].strip()\n",
        "    except Exception as e:\n",
        "        return f\"(Transcription failed: {str(e)})\"\n",
        "\n",
        "def generate_task_if_needed(score, question, job_data):\n",
        "    if score >= 50:\n",
        "        return \"\"\n",
        "\n",
        "    task_prompt = PromptTemplate.from_template(\"\"\"\n",
        "        ### JOB DESCRIPTION:\n",
        "        {job_data}\n",
        "\n",
        "        ### INTERVIEW QUESTION:\n",
        "        {question}\n",
        "\n",
        "        ### INSTRUCTION:\n",
        "        The candidate answered poorly (score < 50).\n",
        "        Generate a single relevant task (coding/math/business) to evaluate their skills related to this question and the job role.\n",
        "\n",
        "        Return ONLY the task instructions in plain text.\n",
        "    \"\"\")\n",
        "    task_text = (task_prompt | llm).invoke({\"job_data\": str(job_data), \"question\": question})\n",
        "    return task_text.content.strip()\n",
        "\n",
        "def generate_questions(cv_text, job_data):\n",
        "    intro_question = [\"Can you introduce yourself?\"]\n",
        "\n",
        "    random_qs = random.sample(\n",
        "        [q for group in question_bank.values() for q in group],\n",
        "        min(5, sum(len(g) for g in question_bank.values()))\n",
        "    )\n",
        "\n",
        "    job_prompt = PromptTemplate.from_template(\"\"\"\n",
        "    Based on this job description, generate 10 diverse interview questions.\n",
        "\n",
        "    ### JOB DESCRIPTION:\n",
        "    {job_data}\n",
        "\n",
        "    ### OUTPUT:\n",
        "    10 questions numbered as a list.\n",
        "    \"\"\")\n",
        "\n",
        "    job_chain = job_prompt | llm | RunnableLambda(lambda x: x.content.strip())\n",
        "    job_output = job_chain.invoke({\"job_data\": str(job_data)})\n",
        "    job_questions = re.findall(r\"\\d+\\.\\s*(.+)\", job_output)\n",
        "\n",
        "    cv_prompt = PromptTemplate.from_template(\"\"\"\n",
        "    Based on this CV, generate 5 interview questions to assess the candidate's relevance and fit.\n",
        "\n",
        "    ### CV:\n",
        "    {cv_text}\n",
        "\n",
        "    ### OUTPUT:\n",
        "    5 questions numbered as a list.\n",
        "    \"\"\")\n",
        "\n",
        "    cv_chain = cv_prompt | llm | RunnableLambda(lambda x: x.content.strip())\n",
        "    cv_output = cv_chain.invoke({\"cv_text\": cv_text})\n",
        "    cv_questions = re.findall(r\"\\d+\\.\\s*(.+)\", cv_output)\n",
        "\n",
        "    combined_qs = []\n",
        "    for i in range(0, 10, 2):\n",
        "        combined_qs.extend(job_questions[i:i+2])\n",
        "        if i // 2 < len(cv_questions):\n",
        "            combined_qs.append(cv_questions[i // 2])\n",
        "\n",
        "    return intro_question + random_qs + combined_qs\n",
        "\n",
        "def download_results():\n",
        "    df = pd.DataFrame(interview_data)\n",
        "    filename = f\"interview_results_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "    df.to_csv(filename, index=False)\n",
        "    return filename\n",
        "\n",
        "def submit_task_answer(task_answer, state):\n",
        "    try:\n",
        "        if not interview_data:\n",
        "            return \"âš ï¸ No interview data found.\"\n",
        "        last_record = interview_data[-1]\n",
        "        last_record[\"task_answer\"] = task_answer\n",
        "        return \"âœ… Task answer submitted and saved.\"\n",
        "    except Exception as e:\n",
        "        return f\"âŒ Error: {str(e)}\"\n",
        "\n",
        "def generate_final_feedback_on_tasks(state):\n",
        "    try:\n",
        "        tasks_data = [record for record in interview_data if record.get(\"task\") and record.get(\"task_answer\")]\n",
        "        if not tasks_data:\n",
        "            return \"No extra tasks were assigned, so no final feedback is needed.\"\n",
        "\n",
        "        task_summaries = \"\\n\\n\".join([\n",
        "            f\"Question: {record['question']}\\n\"\n",
        "            f\"Task: {record['task']}\\n\"\n",
        "            f\"Candidate's Answer: {record['task_answer']}\"\n",
        "            for record in tasks_data\n",
        "        ])\n",
        "\n",
        "        feedback_prompt = PromptTemplate.from_template(\"\"\"\n",
        "        The following are extra tasks given to the candidate during the interview and their submitted answers:\n",
        "\n",
        "        {task_summaries}\n",
        "\n",
        "        ### INSTRUCTION:\n",
        "        Write a final assessment focused ONLY on their extra task performance. Evaluate the quality, correctness, effort, and relevance of the task answers. End with a clear hiring recommendation.\n",
        "        \"\"\")\n",
        "\n",
        "        chain = feedback_prompt | llm | RunnableLambda(lambda x: x.content.strip())\n",
        "        result = chain.invoke({\"task_summaries\": task_summaries})\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return f\"âš ï¸ Failed to generate final feedback: {str(e)}\"\n",
        "\n",
        "# -------------------- Gradio UI --------------------\n",
        "with gr.Blocks(theme='Respair/Shiki@1.2.1') as app:\n",
        "    gr.Markdown(\"\"\"\n",
        "        # ðŸŽ¤ AI Interviewer\n",
        "        Upload your CV, paste a link, add job requirements, and begin an interactive mock interview with voice and text.\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        cv_file = gr.File(label=\"ðŸ“„ Upload CV\")\n",
        "        cv_url = gr.Textbox(label=\"ðŸŒ Or paste CV Link\")\n",
        "\n",
        "    job_input = gr.Textbox(label=\"ðŸ¢ Job Requirements or URL\")\n",
        "    start_btn = gr.Button(\"ðŸš€ Start Interview\")\n",
        "\n",
        "    question_output = gr.Textbox(label=\"ðŸ§  Interview Question\", lines=2)\n",
        "    mic_input = gr.Audio(type=\"filepath\", label=\"ðŸŽ™ï¸ Speak your answer\")\n",
        "    text_input = gr.Textbox(label=\"âœï¸ Or type your answer\")\n",
        "    submit_btn = gr.Button(\"âœ… Submit Answer\")\n",
        "    next_btn = gr.Button(\"â­ï¸ Next Question\")\n",
        "\n",
        "    score_output = gr.Textbox(label=\"ðŸ“Š Score & Feedback\")\n",
        "    task_output = gr.Textbox(label=\"ðŸ§ª Extra Task (if any)\")\n",
        "    task_answer_input = gr.Textbox(label=\"âœï¸ Your Answer to the Task\", lines=4)\n",
        "    submit_task_btn = gr.Button(\"ðŸ“¨ Submit Task Answer\")\n",
        "    task_status = gr.Textbox(label=\"ðŸ“¬ Task Submission Status\", interactive=False)\n",
        "\n",
        "    feedback_output = gr.Textbox(label=\"ðŸ§¾ Final Feedback\")\n",
        "    download_btn = gr.Button(\"ðŸ“¥ Download Full Interview Report\")\n",
        "    download_file = gr.File()\n",
        "    error_box = gr.Textbox(label=\"ðŸš¨ Error Log (if any)\", lines=2, interactive=False)\n",
        "    state = gr.State({})\n",
        "\n",
        "    def start(cv_file, cv_url, job_input):\n",
        "        try:\n",
        "            cv_text = load_cv(cv_file, cv_url)\n",
        "            job_data = extract_job_info(job_input)\n",
        "            questions = generate_questions(cv_text, job_data)\n",
        "            new_state = {\n",
        "                \"cv_text\": cv_text,\n",
        "                \"job_data\": job_data,\n",
        "                \"questions\": questions,\n",
        "                \"current\": 0,\n",
        "                \"answers\": []\n",
        "            }\n",
        "            return questions[0], new_state, \"\"\n",
        "        except Exception as e:\n",
        "            return \"âŒ Error occurred while starting interview.\", {}, str(e)\n",
        "\n",
        "    def submit_answer(audio_path, text, state):\n",
        "        try:\n",
        "            question = state[\"questions\"][state[\"current\"]]\n",
        "            if not text and audio_path:\n",
        "                text = transcribe_audio(audio_path)\n",
        "\n",
        "            answer = text or \"(No valid response)\"\n",
        "            result = ask_next_question(question, answer)\n",
        "            score = result[\"score\"]\n",
        "            feedback = result[\"feedback\"]\n",
        "            task_instruction = generate_task_if_needed(score, question, state[\"job_data\"])\n",
        "\n",
        "            interview_data.append({\n",
        "                \"question\": question,\n",
        "                \"answer\": answer,\n",
        "                \"score\": score,\n",
        "                \"feedback\": feedback,\n",
        "                \"task\": task_instruction,\n",
        "                \"task_answer\": \"\"  # Always include this for consistency\n",
        "            })\n",
        "\n",
        "            state[\"answers\"].append((question, answer, score))\n",
        "            return f\"Score: {score}\\nFeedback: {feedback}\", task_instruction, \"\", state, \"\"\n",
        "        except Exception as e:\n",
        "            return \"\", \"\", \"\", state, str(e)\n",
        "\n",
        "    def go_to_next_question(state):\n",
        "        try:\n",
        "            state[\"current\"] += 1\n",
        "            if state[\"current\"] < len(state[\"questions\"]):\n",
        "                return state[\"questions\"][state[\"current\"]], state, \"\", \"\"\n",
        "            else:\n",
        "                final_summary = generate_final_feedback_on_tasks(state)\n",
        "                return \"âœ… Interview Complete\", state, final_summary, \"\"\n",
        "        except Exception as e:\n",
        "            return \"âŒ Error moving to next question\", state, \"\", str(e)\n",
        "\n",
        "    def download():\n",
        "        try:\n",
        "            return download_results()\n",
        "        except Exception as e:\n",
        "            return str(e)\n",
        "\n",
        "    start_btn.click(fn=start, inputs=[cv_file, cv_url, job_input], outputs=[question_output, state, error_box])\n",
        "    submit_btn.click(fn=submit_answer, inputs=[mic_input, text_input, state], outputs=[score_output, task_output, feedback_output, state, error_box])\n",
        "    next_btn.click(fn=go_to_next_question, inputs=[state], outputs=[question_output, state, feedback_output, error_box])\n",
        "    submit_task_btn.click(fn=submit_task_answer, inputs=[task_answer_input, state], outputs=[task_status])\n",
        "    download_btn.click(fn=download, outputs=download_file)\n",
        "\n",
        "app.launch()"
      ],
      "metadata": {
        "id": "hCnF3zncVoau",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779,
          "referenced_widgets": [
            "510d86b59d674b1ca567abba4876b096",
            "5828ddc0ae2c44659b25b4f5978958bd",
            "b73f046b8ccc42659f4c87ab057f1ad2",
            "86fa16489f1745199ebd7f18475014a5",
            "5f767251b0e145deac9123111e61ab37",
            "fea7aea11b45449e85bf030175c5e1d8",
            "1a0d77ba0bc3451f8133e9de7b6c5ae3",
            "0b700d3f7aee4b949126ad1c72e84367",
            "93697327ca0c47138fe4c31c5a6b42cb",
            "2ca9571144d94a5a844b3f323974656d",
            "971b575132d348ebbb3c16a6c042bb71"
          ]
        },
        "outputId": "a5123a5d-f5d7-4c72-fa57-af6bf3ef8c80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139M/139M [00:02<00:00, 56.7MiB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "theme_schema%401.2.1.json:   0%|          | 0.00/14.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "510d86b59d674b1ca567abba4876b096"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://31e6472ae7d7371047.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://31e6472ae7d7371047.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wC276AAF5CNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# fast api\n"
      ],
      "metadata": {
        "id": "edyjSugr5DCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, UploadFile, File, Form\n",
        "from fastapi.responses import FileResponse, JSONResponse\n",
        "from pydantic import BaseModel\n",
        "import uuid\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import os\n",
        "import mimetypes\n",
        "import fitz  # PyMuPDF\n",
        "import whisper\n",
        "import re\n",
        "import random\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# -------------------- Global Vars --------------------\n",
        "llm = ChatGroq(\n",
        "    temperature=0,\n",
        "    groq_api_key=\"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\",\n",
        "    model_name=\"llama-3.3-70b-versatile\"\n",
        ")\n",
        "\n",
        "model_whisper = whisper.load_model(\"base\")\n",
        "sessions = {}\n",
        "interview_data = {}\n",
        "\n",
        "question_bank = {\n",
        "    \"General & Motivational\": [...],\n",
        "    \"Situational & Skill-Based\": [...],\n",
        "    \"Teamwork & Leadership\": [...],\n",
        "    \"Work Style & Personality\": [...]\n",
        "}\n",
        "\n",
        "# -------------------- Utils --------------------\n",
        "def load_cv(cv_file, cv_url):\n",
        "    if cv_url:\n",
        "        loader = WebBaseLoader(cv_url)\n",
        "        return loader.load().pop().page_content\n",
        "    elif cv_file:\n",
        "        file_type, _ = mimetypes.guess_type(cv_file.filename)\n",
        "        if file_type == 'application/pdf':\n",
        "            try:\n",
        "                doc = fitz.open(stream=cv_file.file.read(), filetype=\"pdf\")\n",
        "                text = \"\\n\".join([page.get_text() for page in doc])\n",
        "                doc.close()\n",
        "                return text\n",
        "            except Exception as e:\n",
        "                return f\"Failed to read PDF: {str(e)}\"\n",
        "        else:\n",
        "            try:\n",
        "                return cv_file.file.read().decode(\"utf-8\")\n",
        "            except:\n",
        "                return \"Unsupported file format or decoding failed.\"\n",
        "    return \"\"\n",
        "\n",
        "def extract_job_info(job_text_or_url):\n",
        "    try:\n",
        "        if job_text_or_url.startswith(\"http\"):\n",
        "            loader = WebBaseLoader(job_text_or_url)\n",
        "            page_data = loader.load().pop().page_content\n",
        "        else:\n",
        "            page_data = job_text_or_url\n",
        "\n",
        "        parser = JsonOutputParser()\n",
        "\n",
        "        prompt = PromptTemplate.from_template(\"\"\"\n",
        "        You are a hiring analyst. Analyze the following job description text and return structured job details in JSON format.\n",
        "\n",
        "        ### INPUT:\n",
        "        {page_data}\n",
        "\n",
        "        ### OUTPUT FORMAT:\n",
        "        {format_instructions}\n",
        "        \"\"\").partial(format_instructions=parser.get_format_instructions())\n",
        "\n",
        "        chain = prompt | llm | RunnableLambda(lambda x: x.content.strip())\n",
        "        result = chain.invoke({'page_data': page_data})\n",
        "        return parser.parse(result)\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"role\": \"Unknown\",\n",
        "            \"experience\": \"Not specified\",\n",
        "            \"skills\": [],\n",
        "            \"description\": page_data[:500] + \"...\"\n",
        "        }\n",
        "\n",
        "def ask_next_question(question, answer):\n",
        "    prompt = PromptTemplate.from_template(\"\"\"\n",
        "        ### QUESTION:\n",
        "        {question}\n",
        "\n",
        "        ### ANSWER:\n",
        "        {answer}\n",
        "\n",
        "        ### INSTRUCTION:\n",
        "        Evaluate the candidate's answer and score it from 0 to 100.\n",
        "\n",
        "        Then, based on the score, craft human-like, professional, and emotionally intelligent feedback:\n",
        "        - If the score is >= 85, give praise and note what stood out.\n",
        "        - If score is 70â€“84, mention it was solid and how to polish it further.\n",
        "        - If 50â€“69, highlight the potential and suggest key improvements.\n",
        "        - If below 50, be honest but empathetic, give constructive criticism, and encouragement.\n",
        "\n",
        "        Return this JSON format:\n",
        "        {{\n",
        "            \"score\": 78,\n",
        "            \"feedback\": \"Your answer was structured and thoughtful. With more specific examples, it could be excellent.\"\n",
        "        }}\n",
        "    \"\"\")\n",
        "\n",
        "    chain = prompt | llm | RunnableLambda(lambda x: x.content.strip())\n",
        "    raw_output = chain.invoke({\"question\": question, \"answer\": answer})\n",
        "    match = re.search(r\"\\{.*\\}\", raw_output, re.DOTALL)\n",
        "    if match:\n",
        "        parser = JsonOutputParser()\n",
        "        return parser.parse(match.group())\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid response format: {raw_output}\")\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    try:\n",
        "        result = model_whisper.transcribe(audio_path)\n",
        "        return result[\"text\"].strip()\n",
        "    except Exception as e:\n",
        "        return f\"(Transcription failed: {str(e)})\"\n",
        "\n",
        "def generate_task_if_needed(score, question, job_data):\n",
        "    if score >= 50:\n",
        "        return \"\"\n",
        "    task_prompt = PromptTemplate.from_template(\"\"\"\n",
        "        ### JOB DESCRIPTION:\n",
        "        {job_data}\n",
        "\n",
        "        ### INTERVIEW QUESTION:\n",
        "        {question}\n",
        "\n",
        "        ### INSTRUCTION:\n",
        "        The candidate answered poorly (score < 50).\n",
        "        Generate a single relevant task (coding/math/business) to evaluate their skills related to this question and the job role.\n",
        "\n",
        "        Return ONLY the task instructions in plain text.\n",
        "    \"\"\")\n",
        "    task_text = (task_prompt | llm).invoke({\"job_data\": str(job_data), \"question\": question})\n",
        "    return task_text.content.strip()\n",
        "\n",
        "def generate_questions(cv_text, job_data):\n",
        "    intro_question = [\"Can you introduce yourself?\"]\n",
        "    random_qs = random.sample(\n",
        "        [q for group in question_bank.values() for q in group],\n",
        "        min(5, sum(len(g) for g in question_bank.values()))\n",
        "    )\n",
        "    job_prompt = PromptTemplate.from_template(\"\"\"\n",
        "    Based on this job description, generate 10 diverse interview questions.\n",
        "\n",
        "    ### JOB DESCRIPTION:\n",
        "    {job_data}\n",
        "\n",
        "    ### OUTPUT:\n",
        "    10 questions numbered as a list.\n",
        "    \"\"\")\n",
        "    job_chain = job_prompt | llm | RunnableLambda(lambda x: x.content.strip())\n",
        "    job_output = job_chain.invoke({\"job_data\": str(job_data)})\n",
        "    job_questions = re.findall(r\"\\d+\\.\\s*(.+)\", job_output)\n",
        "    cv_prompt = PromptTemplate.from_template(\"\"\"\n",
        "    Based on this CV, generate 5 interview questions to assess the candidate's relevance and fit.\n",
        "\n",
        "    ### CV:\n",
        "    {cv_text}\n",
        "\n",
        "    ### OUTPUT:\n",
        "    5 questions numbered as a list.\n",
        "    \"\"\")\n",
        "    cv_chain = cv_prompt | llm | RunnableLambda(lambda x: x.content.strip())\n",
        "    cv_output = cv_chain.invoke({\"cv_text\": cv_text})\n",
        "    cv_questions = re.findall(r\"\\d+\\.\\s*(.+)\", cv_output)\n",
        "    combined_qs = []\n",
        "    for i in range(0, 10, 2):\n",
        "        combined_qs.extend(job_questions[i:i+2])\n",
        "        if i // 2 < len(cv_questions):\n",
        "            combined_qs.append(cv_questions[i // 2])\n",
        "    return intro_question + random_qs + combined_qs\n",
        "\n",
        "def save_interview_csv(session_id):\n",
        "    data = interview_data.get(session_id, [])\n",
        "    df = pd.DataFrame(data)\n",
        "    filename = f\"interview_results_{session_id}.csv\"\n",
        "    df.to_csv(filename, index=False)\n",
        "    return filename\n",
        "\n",
        "# -------------------- FastAPI Endpoints --------------------\n",
        "\n",
        "class AnswerRequest(BaseModel):\n",
        "    session_id: str\n",
        "    audio_path: str = \"\"\n",
        "    text: str = \"\"\n",
        "\n",
        "@app.post(\"/start\")\n",
        "async def start_interview(\n",
        "    job_input: str = Form(...),\n",
        "    cv_file: UploadFile = File(None),\n",
        "    cv_url: str = Form(None)\n",
        "):\n",
        "    cv_text = load_cv(cv_file, cv_url)\n",
        "    job_data = extract_job_info(job_input)\n",
        "    questions = generate_questions(cv_text, job_data)\n",
        "    session_id = str(uuid.uuid4())\n",
        "    sessions[session_id] = {\n",
        "        \"cv_text\": cv_text,\n",
        "        \"job_data\": job_data,\n",
        "        \"questions\": questions,\n",
        "        \"current\": 0,\n",
        "        \"answers\": []\n",
        "    }\n",
        "    interview_data[session_id] = []\n",
        "    return {\"session_id\": session_id, \"question\": questions[0]}\n",
        "\n",
        "@app.post(\"/answer\")\n",
        "async def submit_answer(data: AnswerRequest):\n",
        "    state = sessions[data.session_id]\n",
        "    question = state[\"questions\"][state[\"current\"]]\n",
        "    answer = data.text or transcribe_audio(data.audio_path)\n",
        "    result = ask_next_question(question, answer)\n",
        "    score = result[\"score\"]\n",
        "    feedback = result[\"feedback\"]\n",
        "    task = generate_task_if_needed(score, question, state[\"job_data\"])\n",
        "    interview_data[data.session_id].append({\n",
        "        \"question\": question,\n",
        "        \"answer\": answer,\n",
        "        \"score\": score,\n",
        "        \"feedback\": feedback,\n",
        "        \"task\": task\n",
        "    })\n",
        "    state[\"answers\"].append((question, answer, score))\n",
        "    return {\"score\": score, \"feedback\": feedback, \"task\": task}\n",
        "\n",
        "@app.get(\"/next/{session_id}\")\n",
        "async def next_question(session_id: str):\n",
        "    state = sessions.get(session_id)\n",
        "    if not state:\n",
        "        return JSONResponse(content={\"error\": \"Session not found\"}, status_code=404)\n",
        "    state[\"current\"] += 1\n",
        "    if state[\"current\"] < len(state[\"questions\"]):\n",
        "        return {\"question\": state[\"questions\"][state[\"current\"]]}\n",
        "    else:\n",
        "        return {\"message\": \"Interview complete.\"}\n",
        "\n",
        "@app.get(\"/download/{session_id}\")\n",
        "async def download_results(session_id: str):\n",
        "    filename = save_interview_csv(session_id)\n",
        "    return FileResponse(filename, media_type='text/csv', filename=filename)"
      ],
      "metadata": {
        "id": "OzBUtj0t5CK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# everything Fastapi\n"
      ],
      "metadata": {
        "id": "9F-EJy0655A5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# main.py\n",
        "from fastapi import FastAPI, UploadFile, File, Form\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel\n",
        "from typing import Optional\n",
        "import uuid\n",
        "from utils.interview_logic import (\n",
        "    load_cv,\n",
        "    extract_job_info,\n",
        "    generate_questions,\n",
        "    ask_next_question,\n",
        "    generate_task_if_needed,\n",
        "    transcribe_audio,\n",
        "    download_results,\n",
        "    session_store\n",
        ")\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "class StartInterviewRequest(BaseModel):\n",
        "    job_input: str\n",
        "    cv_url: Optional[str] = None\n",
        "\n",
        "class SubmitAnswerRequest(BaseModel):\n",
        "    session_id: str\n",
        "    answer_text: Optional[str] = None\n",
        "\n",
        "@app.post(\"/start\")\n",
        "async def start_interview(\n",
        "    job_input: str = Form(...),\n",
        "    cv_file: Optional[UploadFile] = File(None),\n",
        "    cv_url: Optional[str] = Form(None)\n",
        "):\n",
        "    try:\n",
        "        cv_text = await load_cv(cv_file, cv_url)\n",
        "        job_data = extract_job_info(job_input)\n",
        "        questions = generate_questions(cv_text, job_data)\n",
        "\n",
        "        session_id = str(uuid.uuid4())\n",
        "        session_store[session_id] = {\n",
        "            \"cv_text\": cv_text,\n",
        "            \"job_data\": job_data,\n",
        "            \"questions\": questions,\n",
        "            \"current\": 0,\n",
        "            \"answers\": [],\n",
        "            \"results\": []\n",
        "        }\n",
        "\n",
        "        return {\"session_id\": session_id, \"question\": questions[0]}\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@app.post(\"/answer\")\n",
        "async def submit_answer(\n",
        "    session_id: str = Form(...),\n",
        "    answer_text: Optional[str] = Form(None),\n",
        "    audio_file: Optional[UploadFile] = File(None)\n",
        "):\n",
        "    try:\n",
        "        session = session_store.get(session_id)\n",
        "        if not session:\n",
        "            return {\"error\": \"Invalid session ID\"}\n",
        "\n",
        "        question = session[\"questions\"][session[\"current\"]]\n",
        "\n",
        "        if not answer_text and audio_file:\n",
        "            audio_path = f\"temp_audio/{uuid.uuid4()}.mp3\"\n",
        "            with open(audio_path, \"wb\") as f:\n",
        "                f.write(await audio_file.read())\n",
        "            answer_text = transcribe_audio(audio_path)\n",
        "\n",
        "        if not answer_text:\n",
        "            return {\"error\": \"No answer provided\"}\n",
        "\n",
        "        result = ask_next_question(question, answer_text)\n",
        "        task = generate_task_if_needed(result[\"score\"], question, session[\"job_data\"])\n",
        "\n",
        "        session[\"results\"].append({\n",
        "            \"question\": question,\n",
        "            \"answer\": answer_text,\n",
        "            \"score\": result[\"score\"],\n",
        "            \"feedback\": result[\"feedback\"],\n",
        "            \"task\": task\n",
        "        })\n",
        "\n",
        "        session[\"answers\"].append((question, answer_text, result[\"score\"]))\n",
        "\n",
        "        return {\n",
        "            \"score\": result[\"score\"],\n",
        "            \"feedback\": result[\"feedback\"],\n",
        "            \"task\": task\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@app.get(\"/next/{session_id}\")\n",
        "async def next_question(session_id: str):\n",
        "    try:\n",
        "        session = session_store.get(session_id)\n",
        "        if not session:\n",
        "            return {\"error\": \"Invalid session ID\"}\n",
        "\n",
        "        session[\"current\"] += 1\n",
        "        if session[\"current\"] < len(session[\"questions\"]):\n",
        "            return {\"question\": session[\"questions\"][session[\"current\"]]}\n",
        "        else:\n",
        "            return {\"message\": \"Interview Complete\"}\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@app.get(\"/download/{session_id}\")\n",
        "async def download(session_id: str):\n",
        "    try:\n",
        "        session = session_store.get(session_id)\n",
        "        if not session:\n",
        "            return {\"error\": \"Invalid session ID\"}\n",
        "        path = download_results(session[\"results\"])\n",
        "        return {\"file_path\": path}\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "\n",
        "# utils/interview_logic.py\n",
        "import mimetypes\n",
        "import fitz\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "import whisper\n",
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "llm = ChatGroq(\n",
        "    temperature=0,\n",
        "    groq_api_key=\"your-groq-key\",\n",
        "    model_name=\"llama-3.3-70b-versatile\"\n",
        ")\n",
        "model_whisper = whisper.load_model(\"base\")\n",
        "\n",
        "question_bank = {\n",
        "    \"General & Motivational\": [\n",
        "        \"Why do you want to join this company?\",\n",
        "        \"What motivates you to come to work every day?\",\n",
        "        \"What makes you different from others?\",\n",
        "        \"Where do you see yourself in 5 years?\",\n",
        "        \"Why should we hire you?\"\n",
        "    ],\n",
        "    \"Situational & Skill-Based\": [\n",
        "        \"Describe a time you handled failure.\",\n",
        "        \"Tell me about a tight deadline situation.\",\n",
        "        \"Describe a challenge at work and how you overcame it.\",\n",
        "        \"Have you solved a problem without full info?\",\n",
        "        \"How do you deal with stress?\"\n",
        "    ],\n",
        "    \"Teamwork & Leadership\": [\n",
        "        \"How would teammates describe you?\",\n",
        "        \"Tell me about a team conflict you resolved.\",\n",
        "        \"Have you ever led a team? What was your approach?\",\n",
        "        \"How do you give/receive feedback?\"\n",
        "    ],\n",
        "    \"Work Style & Personality\": [\n",
        "        \"How do you stay organized?\",\n",
        "        \"What's your strength and weakness?\",\n",
        "        \"Do you prefer team or solo work?\",\n",
        "        \"How do you keep up with trends?\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "session_store = {}\n",
        "\n",
        "async def load_cv(cv_file=None, cv_url=None):\n",
        "    if cv_url:\n",
        "        loader = WebBaseLoader(cv_url)\n",
        "        return loader.load().pop().page_content\n",
        "    elif cv_file:\n",
        "        file_type, _ = mimetypes.guess_type(cv_file.filename)\n",
        "        if file_type == 'application/pdf':\n",
        "            try:\n",
        "                doc = fitz.open(stream=await cv_file.read(), filetype=\"pdf\")\n",
        "                text = \"\\n\".join([page.get_text() for page in doc])\n",
        "                doc.close()\n",
        "                return text\n",
        "            except Exception as e:\n",
        "                return f\"Failed to read PDF: {str(e)}\"\n",
        "        else:\n",
        "            try:\n",
        "                return (await cv_file.read()).decode(\"utf-8\")\n",
        "            except:\n",
        "                return \"Unsupported file format or decoding failed.\"\n",
        "    return \"\"\n",
        "\n",
        "def extract_job_info(job_text_or_url):\n",
        "    try:\n",
        "        if job_text_or_url.startswith(\"http\"):\n",
        "            loader = WebBaseLoader(job_text_or_url)\n",
        "            page_data = loader.load().pop().page_content\n",
        "        else:\n",
        "            page_data = job_text_or_url\n",
        "\n",
        "        parser = JsonOutputParser()\n",
        "        prompt = PromptTemplate.from_template(\"\"\"\n",
        "        You are a hiring analyst. Analyze the job description and return structured job details in JSON.\n",
        "        ### INPUT:\n",
        "        {page_data}\n",
        "        ### OUTPUT FORMAT:\n",
        "        {format_instructions}\n",
        "        \"\"\").partial(format_instructions=parser.get_format_instructions())\n",
        "\n",
        "        chain = prompt | llm | RunnableLambda(lambda x: x.content.strip())\n",
        "        result = chain.invoke({'page_data': page_data})\n",
        "        return parser.parse(result)\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"role\": \"Unknown\",\n",
        "            \"experience\": \"Not specified\",\n",
        "            \"skills\": [],\n",
        "            \"description\": job_text_or_url[:500] + \"...\"\n",
        "        }\n",
        "\n",
        "def generate_questions(cv_text, job_data):\n",
        "    intro = [\"Can you introduce yourself?\"]\n",
        "    random_qs = random.sample([q for g in question_bank.values() for q in g], 5)\n",
        "\n",
        "    job_prompt = PromptTemplate.from_template(\"\"\"\n",
        "    Based on the job description, generate 10 diverse interview questions.\n",
        "    ### JOB:\n",
        "    {job_data}\n",
        "    ### OUTPUT:\n",
        "    1. ...\n",
        "    \"\"\")\n",
        "    job_output = (job_prompt | llm | RunnableLambda(lambda x: x.content.strip())).invoke({\"job_data\": str(job_data)})\n",
        "    job_qs = re.findall(r\"\\d+\\.\\s*(.+)\", job_output)\n",
        "\n",
        "    cv_prompt = PromptTemplate.from_template(\"\"\"\n",
        "    Based on the CV, generate 5 interview questions to assess fit.\n",
        "    ### CV:\n",
        "    {cv_text}\n",
        "    ### OUTPUT:\n",
        "    1. ...\n",
        "    \"\"\")\n",
        "    cv_output = (cv_prompt | llm | RunnableLambda(lambda x: x.content.strip())).invoke({\"cv_text\": cv_text})\n",
        "    cv_qs = re.findall(r\"\\d+\\.\\s*(.+)\", cv_output)\n",
        "\n",
        "    combined = []\n",
        "    for i in range(0, 10, 2):\n",
        "        combined.extend(job_qs[i:i+2])\n",
        "        if i // 2 < len(cv_qs):\n",
        "            combined.append(cv_qs[i // 2])\n",
        "\n",
        "    return intro + random_qs + combined\n",
        "\n",
        "def ask_next_question(question, answer):\n",
        "    prompt = PromptTemplate.from_template(\"\"\"\n",
        "    ### QUESTION:\n",
        "    {question}\n",
        "\n",
        "    ### ANSWER:\n",
        "    {answer}\n",
        "\n",
        "    ### INSTRUCTION:\n",
        "    Score (0â€“100) and give professional feedback.\n",
        "\n",
        "    Return JSON:\n",
        "    {\n",
        "        \"score\": 78,\n",
        "        \"feedback\": \"Your answer was structured and thoughtful. Add examples.\"\n",
        "    }\n",
        "    \"\"\")\n",
        "\n",
        "    chain = prompt | llm | RunnableLambda(lambda x: x.content.strip())\n",
        "    output = chain.invoke({\"question\": question, \"answer\": answer})\n",
        "    match = re.search(r\"\\{.*\\}\", output, re.DOTALL)\n",
        "    parser = JsonOutputParser()\n",
        "    return parser.parse(match.group()) if match else {\"score\": 0, \"feedback\": \"Invalid format\"}\n",
        "\n",
        "def generate_task_if_needed(score, question, job_data):\n",
        "    if score >= 50:\n",
        "        return \"\"\n",
        "    prompt = PromptTemplate.from_template(\"\"\"\n",
        "    ### JOB:\n",
        "    {job_data}\n",
        "    ### QUESTION:\n",
        "    {question}\n",
        "    ### INSTRUCTION:\n",
        "    Candidate scored < 50. Give one task to test their skill.\n",
        "    \"\"\")\n",
        "    task = (prompt | llm).invoke({\"job_data\": str(job_data), \"question\": question})\n",
        "    return task.content.strip()\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    try:\n",
        "        result = model_whisper.transcribe(audio_path)\n",
        "        return result[\"text\"].strip()\n",
        "    except Exception as e:\n",
        "        return f\"(Transcription failed: {str(e)})\"\n",
        "\n",
        "def download_results(results):\n",
        "    df = pd.DataFrame(results)\n",
        "    filename = f\"interview_results_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "    df.to_csv(filename, index=False)\n",
        "    return filename\n"
      ],
      "metadata": {
        "id": "rppQ1APT52go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8B9-L_zs0-Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fb82Rf2u0-Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9lTvUa250-GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BqeCQ8uh0-Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5zGmOvUE0-BK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P1pHQZB609-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fV5IAV_7098i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}