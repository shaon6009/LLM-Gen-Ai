{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d3e3498444d14409aa0ba26cf3903b64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61f55ff4fb2f431b966fec0f16f36756",
              "IPY_MODEL_5a405e971dec47d1bbc1f2969ed18b58",
              "IPY_MODEL_8d4b36ac16a141fc96e794fda8a664d0"
            ],
            "layout": "IPY_MODEL_a0456fd70be14bcc9259f414b4cb9019"
          }
        },
        "61f55ff4fb2f431b966fec0f16f36756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c73e41773373439a978bed03b8787161",
            "placeholder": "​",
            "style": "IPY_MODEL_1fb6fa9de2fd4bb9879b50010f9e4e1d",
            "value": "theme_schema%401.2.1.json: 100%"
          }
        },
        "5a405e971dec47d1bbc1f2969ed18b58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c02bcc689b0049f690b7377e29dc2a74",
            "max": 14459,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be61009c061f4b5c931976a966f33b2d",
            "value": 14459
          }
        },
        "8d4b36ac16a141fc96e794fda8a664d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddf46194bb5242a8a07ea28999aaf61c",
            "placeholder": "​",
            "style": "IPY_MODEL_4518409e5ae24457b0ed47aed8e1da78",
            "value": " 14.5k/14.5k [00:00&lt;00:00, 1.03MB/s]"
          }
        },
        "a0456fd70be14bcc9259f414b4cb9019": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c73e41773373439a978bed03b8787161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fb6fa9de2fd4bb9879b50010f9e4e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c02bcc689b0049f690b7377e29dc2a74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be61009c061f4b5c931976a966f33b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ddf46194bb5242a8a07ea28999aaf61c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4518409e5ae24457b0ed47aed8e1da78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install langchain langchain_core langchain_groq langchain_community langgraph gradio\n",
        "!pip install gradio pandas uuid chromadb langchain langchain-community langchain-core pymupdf openai-whisper"
      ],
      "metadata": {
        "id": "CJDt8ZCC5JSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(\n",
        "    temperature=0,\n",
        "    groq_api_key=\"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\",\n",
        "    model_name=\"llama-3.3-70b-versatile\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "Hu9lIHFbTPW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import uuid\n",
        "import random\n",
        "import chromadb\n",
        "import datetime\n",
        "import fitz\n",
        "import mimetypes\n",
        "import whisper\n",
        "import re\n",
        "import time\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "# -------------------- LLM Setup --------------------\n",
        "llm = ChatGroq(\n",
        "    temperature=0,\n",
        "    groq_api_key=\"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\",\n",
        "    model_name=\"llama-3.3-70b-versatile\"\n",
        ")\n",
        "\n",
        "model_whisper = whisper.load_model(\"base\")\n",
        "\n",
        "# -------------------- Question Bank --------------------\n",
        "question_bank = {\n",
        "    \"General & Motivational\": [\n",
        "        \"Can you introduce yourself?\", \"Why do you want to join this company?\",\n",
        "        \"What motivates you to come to work every day?\", \"What makes you different from others?\",\n",
        "        \"Where do you see yourself in 5 years?\", \"Why should we hire you?\"\n",
        "    ],\n",
        "    \"Situational & Skill-Based\": [\n",
        "        \"Describe a time you handled failure.\", \"Tell me about a tight deadline situation.\",\n",
        "        \"Describe a challenge at work and how you overcame it.\",\n",
        "        \"Have you solved a problem without full info?\", \"How do you deal with stress?\"\n",
        "    ],\n",
        "    \"Teamwork & Leadership\": [\n",
        "        \"How would teammates describe you?\", \"Tell me about a team conflict you resolved.\",\n",
        "        \"Have you ever led a team? What was your approach?\", \"How do you give/receive feedback?\"\n",
        "    ],\n",
        "    \"Work Style & Personality\": [\n",
        "        \"How do you stay organized?\", \"What's your strength and weakness?\",\n",
        "        \"Do you prefer team or solo work?\", \"How do you keep up with trends?\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# -------------------- Utilities --------------------\n",
        "def load_cv(cv_file=None, cv_url=None):\n",
        "    if cv_url:\n",
        "        loader = WebBaseLoader(cv_url)\n",
        "        return loader.load().pop().page_content\n",
        "    elif cv_file:\n",
        "        file_type, _ = mimetypes.guess_type(cv_file.name)\n",
        "        if file_type == 'application/pdf':\n",
        "            try:\n",
        "                doc = fitz.open(cv_file.name)\n",
        "                text = \"\\n\".join([page.get_text() for page in doc])\n",
        "                doc.close()\n",
        "                return text\n",
        "            except Exception as e:\n",
        "                return f\"Failed to read PDF: {str(e)}\"\n",
        "        else:\n",
        "            try:\n",
        "                return cv_file.read().decode(\"utf-8\")\n",
        "            except:\n",
        "                return \"Unsupported file format or decoding failed.\"\n",
        "    return \"\"\n",
        "\n",
        "def extract_job_info(job_text_or_url):\n",
        "    try:\n",
        "        if job_text_or_url.startswith(\"http\"):\n",
        "            loader = WebBaseLoader(job_text_or_url)\n",
        "            page_data = loader.load().pop().page_content\n",
        "        else:\n",
        "            page_data = job_text_or_url\n",
        "\n",
        "        parser = JsonOutputParser()\n",
        "\n",
        "        prompt = PromptTemplate.from_template(\"\"\"\n",
        "        You are a hiring analyst. Analyze the following job description text and return structured job details in JSON format.\n",
        "\n",
        "        ### INPUT:\n",
        "        {page_data}\n",
        "\n",
        "        ### OUTPUT FORMAT:\n",
        "        {format_instructions}\n",
        "        \"\"\").partial(format_instructions=parser.get_format_instructions())\n",
        "\n",
        "        chain = prompt | llm | RunnableLambda(lambda x: x.content.strip())\n",
        "        result = chain.invoke({'page_data': page_data})\n",
        "        return parser.parse(result)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ Failed to extract job info:\", str(e))\n",
        "        return {\n",
        "            \"role\": \"Unknown\",\n",
        "            \"experience\": \"Not specified\",\n",
        "            \"skills\": [],\n",
        "            \"description\": page_data[:500] + \"...\"\n",
        "        }\n",
        "\n",
        "def generate_contextual_question(state):\n",
        "    prompt = PromptTemplate.from_template(\"\"\"\n",
        "        Based on the job description and the candidate's resume, generate a unique and non-repetitive interview question\n",
        "        that hasn't already been asked. Focus on assessing suitability for the role.\n",
        "\n",
        "        ### JOB DESCRIPTION:\n",
        "        {job_data}\n",
        "\n",
        "        ### CV TEXT:\n",
        "        {cv_text}\n",
        "\n",
        "        ### ALREADY ASKED:\n",
        "        {already_asked}\n",
        "\n",
        "        Return only the new question.\n",
        "    \"\"\")\n",
        "\n",
        "    already_asked = \"\\n\".join(state[\"questions\"])\n",
        "\n",
        "    question = (prompt | llm | RunnableLambda(lambda x: x.content.strip())).invoke({\n",
        "        \"job_data\": str(state[\"job_data\"]),\n",
        "        \"cv_text\": state[\"cv_text\"],\n",
        "        \"already_asked\": already_asked\n",
        "    })\n",
        "\n",
        "    return question\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    try:\n",
        "        result = model_whisper.transcribe(audio_path)\n",
        "        return result[\"text\"].strip()\n",
        "    except Exception as e:\n",
        "        return f\"(Transcription failed: {str(e)})\"\n",
        "\n",
        "def ask_next_question(question, answer):\n",
        "    prompt = PromptTemplate.from_template(\"\"\"\n",
        "        ### QUESTION:\n",
        "        {question}\n",
        "\n",
        "        ### ANSWER:\n",
        "        {answer}\n",
        "\n",
        "        ### INSTRUCTION:\n",
        "        Score the answer from 0 to 100 based on clarity, relevance, and confidence.\n",
        "        Give short feedback and return JSON:\n",
        "        {{\"score\": 85, \"feedback\": \"Good explanation but lacked structure.\"}}\n",
        "    \"\"\")\n",
        "    chain = prompt | llm | RunnableLambda(lambda x: x.content.strip())\n",
        "    raw_output = chain.invoke({\"question\": question, \"answer\": answer})\n",
        "\n",
        "    match = re.search(r\"\\{.*\\}\", raw_output, re.DOTALL)\n",
        "    if match:\n",
        "        json_part = match.group()\n",
        "        parser = JsonOutputParser()\n",
        "        return parser.parse(json_part)\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid response format: {raw_output}\")\n",
        "\n",
        "def generate_follow_up(score, job_data, cv_text):\n",
        "    if score < 60:\n",
        "        task_prompt = PromptTemplate.from_template(\"\"\"\n",
        "            ### JOB:\n",
        "            {job_data}\n",
        "\n",
        "            ### INSTRUCTION:\n",
        "            Generate a task (coding/math/business) suitable for this role.\n",
        "            Return JSON: {{\"task_type\": \"math\", \"instructions\": \"Solve this...\"}}\n",
        "        \"\"\")\n",
        "        task_result = (task_prompt | llm | RunnableLambda(lambda x: x.content.strip())).invoke({\"job_data\": str(job_data)})\n",
        "        parser = JsonOutputParser()\n",
        "        task_data = parser.parse(task_result)\n",
        "\n",
        "        feedback_prompt = PromptTemplate.from_template(\"\"\"\n",
        "            ### CV:\n",
        "            {cv_text}\n",
        "\n",
        "            ### INSTRUCTION:\n",
        "            Give feedback on areas of improvement in 3 lines.\n",
        "        \"\"\")\n",
        "        feedback_result = (feedback_prompt | llm).invoke({\"cv_text\": cv_text})\n",
        "        return task_data, feedback_result.content.strip()\n",
        "    return {}, \"\"\n",
        "\n",
        "def download_results():\n",
        "    df = pd.DataFrame(interview_data)\n",
        "    filename = f\"interview_results_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "    df.to_csv(filename, index=False)\n",
        "    return filename\n",
        "\n",
        "# -------------------- Interview Logic --------------------\n",
        "interview_data = []\n",
        "\n",
        "def start(cv_file, cv_url, job_input, timer_minutes):\n",
        "    try:\n",
        "        cv_text = load_cv(cv_file, cv_url)\n",
        "        job_data = extract_job_info(job_input)\n",
        "\n",
        "        intro_q = [\"Can you introduce yourself?\"]\n",
        "        general_qs = random.sample(question_bank[\"General & Motivational\"][1:], 3)\n",
        "        static_questions = intro_q + general_qs\n",
        "\n",
        "        start_time = time.time()\n",
        "        duration = int(timer_minutes) * 60\n",
        "\n",
        "        new_state = {\n",
        "            \"cv_text\": cv_text,\n",
        "            \"job_data\": job_data,\n",
        "            \"questions\": static_questions,\n",
        "            \"current\": 0,\n",
        "            \"answers\": [],\n",
        "            \"start_time\": start_time,\n",
        "            \"duration\": duration\n",
        "        }\n",
        "\n",
        "        return \"👋 Hello! Let's start with an easy one: Can you introduce yourself?\", new_state, \"\"\n",
        "    except Exception as e:\n",
        "        return \"❌ Error occurred while starting interview.\", {}, str(e)\n",
        "\n",
        "def submit_answer(audio_path, text, state):\n",
        "    try:\n",
        "        question = state[\"questions\"][state[\"current\"]]\n",
        "        if not text and audio_path:\n",
        "            text = transcribe_audio(audio_path)\n",
        "\n",
        "        answer = text or \"(No valid response)\"\n",
        "        result = ask_next_question(question, answer)\n",
        "        score = result[\"score\"]\n",
        "        feedback = result[\"feedback\"]\n",
        "\n",
        "        interview_data.append({\n",
        "            \"question\": question,\n",
        "            \"answer\": answer,\n",
        "            \"score\": score,\n",
        "            \"feedback\": feedback\n",
        "        })\n",
        "\n",
        "        state[\"answers\"].append((question, answer, score))\n",
        "\n",
        "        avg_score = sum(s for _, _, s in state[\"answers\"]) / len(state[\"answers\"])\n",
        "        task, final_feedback = generate_follow_up(avg_score, state[\"job_data\"], state[\"cv_text\"])\n",
        "\n",
        "        return f\"Score: {score}\\nFeedback: {feedback}\", task.get(\"instructions\", \"\"), final_feedback, state, \"\"\n",
        "    except Exception as e:\n",
        "        return \"\", \"\", \"\", state, str(e)\n",
        "\n",
        "def go_to_next_question(state):\n",
        "    try:\n",
        "        if time.time() - state[\"start_time\"] > state[\"duration\"]:\n",
        "            return \"⏳ Interview time is over. Thank you!\", state, \"\"\n",
        "\n",
        "        state[\"current\"] += 1\n",
        "\n",
        "        if state[\"current\"] < len(state[\"questions\"]):\n",
        "            return state[\"questions\"][state[\"current\"]], state, \"\"\n",
        "        else:\n",
        "            new_q = generate_contextual_question(state)\n",
        "            state[\"questions\"].append(new_q)\n",
        "            return new_q, state, \"\"\n",
        "    except Exception as e:\n",
        "        return \"❌ Error getting next question\", state, str(e)\n",
        "\n",
        "def download():\n",
        "    try:\n",
        "        return download_results()\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "# -------------------- Gradio UI --------------------\n",
        "with gr.Blocks(theme='Respair/Shiki@1.2.1') as app:\n",
        "    gr.Markdown(\"\"\"\n",
        "        # 🎤 AI Interviewer\n",
        "        Upload your CV, paste a link, add job requirements, and begin an interactive mock interview with voice and text.\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        cv_file = gr.File(label=\"📄 Upload CV\")\n",
        "        cv_url = gr.Textbox(label=\"🌐 Or paste CV Link\")\n",
        "\n",
        "    job_input = gr.Textbox(label=\"🏢 Job Requirements or URL\")\n",
        "    timer_dropdown = gr.Dropdown(choices=[\"20\", \"40\", \"60\", \"80\"], label=\"⏱️ Interview Duration (minutes)\", value=\"20\")\n",
        "\n",
        "    start_btn = gr.Button(\"🚀 Start Interview\")\n",
        "\n",
        "    question_output = gr.Textbox(label=\"🧠 Interview Question\", lines=2)\n",
        "    mic_input = gr.Audio(type=\"filepath\", label=\"🎙️ Speak your answer\")\n",
        "    text_input = gr.Textbox(label=\"✍️ Or type your answer\")\n",
        "    submit_btn = gr.Button(\"✅ Submit Answer\")\n",
        "    next_btn = gr.Button(\"➡️ Next Question\")\n",
        "    pass_btn = gr.Button(\"⏭️ Pass This Question\")\n",
        "\n",
        "    score_output = gr.Textbox(label=\"📊 Score & Feedback\")\n",
        "    task_output = gr.Textbox(label=\"🧪 Extra Task (if any)\")\n",
        "    feedback_output = gr.Textbox(label=\"🧾 Final Feedback\")\n",
        "    download_btn = gr.Button(\"📥 Download Full Interview Report\")\n",
        "    download_file = gr.File()\n",
        "    error_box = gr.Textbox(label=\"🚨 Error Log (if any)\", lines=2, interactive=False)\n",
        "    state = gr.State({})\n",
        "\n",
        "    start_btn.click(fn=start, inputs=[cv_file, cv_url, job_input, timer_dropdown], outputs=[question_output, state, error_box])\n",
        "    submit_btn.click(fn=submit_answer, inputs=[mic_input, text_input, state], outputs=[score_output, task_output, feedback_output, state, error_box])\n",
        "    next_btn.click(fn=go_to_next_question, inputs=[state], outputs=[question_output, state, error_box])\n",
        "    pass_btn.click(fn=go_to_next_question, inputs=[state], outputs=[question_output, state, error_box])\n",
        "    download_btn.click(fn=download, outputs=download_file)\n",
        "\n",
        "app.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816,
          "referenced_widgets": [
            "d3e3498444d14409aa0ba26cf3903b64",
            "61f55ff4fb2f431b966fec0f16f36756",
            "5a405e971dec47d1bbc1f2969ed18b58",
            "8d4b36ac16a141fc96e794fda8a664d0",
            "a0456fd70be14bcc9259f414b4cb9019",
            "c73e41773373439a978bed03b8787161",
            "1fb6fa9de2fd4bb9879b50010f9e4e1d",
            "c02bcc689b0049f690b7377e29dc2a74",
            "be61009c061f4b5c931976a966f33b2d",
            "ddf46194bb5242a8a07ea28999aaf61c",
            "4518409e5ae24457b0ed47aed8e1da78"
          ]
        },
        "id": "t0YyVwG2HRgE",
        "outputId": "c590a3c0-afab-4f2e-84e5-7ddf57dfab24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
            "100%|███████████████████████████████████████| 139M/139M [00:03<00:00, 40.8MiB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "theme_schema%401.2.1.json:   0%|          | 0.00/14.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3e3498444d14409aa0ba26cf3903b64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://fbfcf3ac24c8d48e2c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://fbfcf3ac24c8d48e2c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XURUJpS7SR0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xoSVkWhVSRx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ByzwOTXUSRvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ta5bW4TPSRs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JOHOOeVOSRqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VBjEG6QySRn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tqo6FT4USRld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9DM1QZmjSRi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zNJDkIJGSRgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I9BVNl7rubPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SoXydF5yubKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JVk3EAAeubHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5tbHcka2ubFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ieZoQD__ubCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KsEFcU2DubAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YO6x1sgOua92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h8a8kSAIua7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oYowlOMnua40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p6auDU0Gua2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rk3H1RV4uavW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ZFR8IXQSReF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import uuid\n",
        "import random\n",
        "import chromadb\n",
        "import datetime\n",
        "import fitz  # PyMuPDF for PDF reading\n",
        "import mimetypes\n",
        "import whisper\n",
        "import re\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "# -------------------- LLM Setup --------------------\n",
        "llm = ChatGroq(\n",
        "    temperature=0,\n",
        "    groq_api_key=\"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\",\n",
        "    model_name=\"llama-3.3-70b-versatile\"\n",
        ")\n",
        "\n",
        "model_whisper = whisper.load_model(\"base\")\n",
        "\n",
        "# -------------------- Question Bank --------------------\n",
        "question_bank = {\n",
        "    \"General & Motivational\": [\n",
        "        \"Can you introduce yourself?\", \"Why do you want to join this company?\",\n",
        "        \"What motivates you to come to work every day?\", \"What makes you different from others?\",\n",
        "        \"Where do you see yourself in 5 years?\", \"Why should we hire you?\"\n",
        "    ],\n",
        "    \"Situational & Skill-Based\": [\n",
        "        \"Describe a time you handled failure.\", \"Tell me about a tight deadline situation.\",\n",
        "        \"Describe a challenge at work and how you overcame it.\",\n",
        "        \"Have you solved a problem without full info?\", \"How do you deal with stress?\"\n",
        "    ],\n",
        "    \"Teamwork & Leadership\": [\n",
        "        \"How would teammates describe you?\", \"Tell me about a team conflict you resolved.\",\n",
        "        \"Have you ever led a team? What was your approach?\", \"How do you give/receive feedback?\"\n",
        "    ],\n",
        "    \"Work Style & Personality\": [\n",
        "        \"How do you stay organized?\", \"What's your strength and weakness?\",\n",
        "        \"Do you prefer team or solo work?\", \"How do you keep up with trends?\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "def get_random_questions(count=6):\n",
        "    all_qs = [q for group in question_bank.values() for q in group]\n",
        "    return random.sample(all_qs, min(count, len(all_qs)))\n",
        "\n",
        "# -------------------- Loaders --------------------\n",
        "def load_cv(cv_file=None, cv_url=None):\n",
        "    if cv_url:\n",
        "        loader = WebBaseLoader(cv_url)\n",
        "        return loader.load().pop().page_content\n",
        "    elif cv_file:\n",
        "        file_type, _ = mimetypes.guess_type(cv_file.name)\n",
        "        if file_type == 'application/pdf':\n",
        "            try:\n",
        "                doc = fitz.open(cv_file.name)\n",
        "                text = \"\\n\".join([page.get_text() for page in doc])\n",
        "                doc.close()\n",
        "                return text\n",
        "            except Exception as e:\n",
        "                return f\"Failed to read PDF: {str(e)}\"\n",
        "        else:\n",
        "            try:\n",
        "                return cv_file.read().decode(\"utf-8\")\n",
        "            except:\n",
        "                return \"Unsupported file format or decoding failed.\"\n",
        "    return \"\"\n",
        "\n",
        "def extract_job_info(job_text_or_url):\n",
        "    try:\n",
        "        if job_text_or_url.startswith(\"http\"):\n",
        "            loader = WebBaseLoader(job_text_or_url)\n",
        "            page_data = loader.load().pop().page_content\n",
        "        else:\n",
        "            page_data = job_text_or_url\n",
        "\n",
        "        parser = JsonOutputParser()\n",
        "\n",
        "        prompt = PromptTemplate.from_template(\"\"\"\n",
        "        You are a hiring analyst. Analyze the following job description text and return structured job details in JSON format.\n",
        "\n",
        "        ### INPUT:\n",
        "        {page_data}\n",
        "\n",
        "        ### OUTPUT FORMAT:\n",
        "        {format_instructions}\n",
        "        \"\"\").partial(format_instructions=parser.get_format_instructions())\n",
        "\n",
        "        chain = prompt | llm | RunnableLambda(lambda x: x.content.strip())\n",
        "        result = chain.invoke({'page_data': page_data})\n",
        "        return parser.parse(result)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ Failed to extract job info:\", str(e))\n",
        "        return {\n",
        "            \"role\": \"Unknown\",\n",
        "            \"experience\": \"Not specified\",\n",
        "            \"skills\": [],\n",
        "            \"description\": page_data[:500] + \"...\"\n",
        "        }\n",
        "\n",
        "# -------------------- Interview Logic --------------------\n",
        "interview_data = []\n",
        "\n",
        "def ask_next_question(question, answer):\n",
        "    prompt = PromptTemplate.from_template(\"\"\"\n",
        "        ### QUESTION:\n",
        "        {question}\n",
        "\n",
        "        ### ANSWER:\n",
        "        {answer}\n",
        "\n",
        "        ### INSTRUCTION:\n",
        "        Score the answer from 0 to 100 based on clarity, relevance, and confidence.\n",
        "        Give short feedback and return JSON:\n",
        "        {{\"score\": 85, \"feedback\": \"Good explanation but lacked structure.\"}}\n",
        "    \"\"\")\n",
        "    chain = prompt | llm | RunnableLambda(lambda x: x.content.strip())\n",
        "    raw_output = chain.invoke({\"question\": question, \"answer\": answer})\n",
        "\n",
        "    match = re.search(r\"\\{.*\\}\", raw_output, re.DOTALL)\n",
        "    if match:\n",
        "        json_part = match.group()\n",
        "        parser = JsonOutputParser()\n",
        "        return parser.parse(json_part)\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid response format: {raw_output}\")\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    try:\n",
        "        result = model_whisper.transcribe(audio_path)\n",
        "        return result[\"text\"].strip()\n",
        "    except Exception as e:\n",
        "        return f\"(Transcription failed: {str(e)})\"\n",
        "\n",
        "def generate_follow_up(score, job_data, cv_text):\n",
        "    if score < 60:\n",
        "        task_prompt = PromptTemplate.from_template(\"\"\"\n",
        "            ### JOB:\n",
        "            {job_data}\n",
        "\n",
        "            ### INSTRUCTION:\n",
        "            Generate a task (coding/math/business) suitable for this role.\n",
        "            Return JSON: {{\"task_type\": \"math\", \"instructions\": \"Solve this...\"}}\n",
        "        \"\"\")\n",
        "        task_result = (task_prompt | llm | RunnableLambda(lambda x: x.content.strip())).invoke({\"job_data\": str(job_data)})\n",
        "        parser = JsonOutputParser()\n",
        "        task_data = parser.parse(task_result)\n",
        "\n",
        "        feedback_prompt = PromptTemplate.from_template(\"\"\"\n",
        "            ### CV:\n",
        "            {cv_text}\n",
        "\n",
        "            ### INSTRUCTION:\n",
        "            Give feedback on areas of improvement in 3 lines.\n",
        "        \"\"\")\n",
        "        feedback_result = (feedback_prompt | llm).invoke({\"cv_text\": cv_text})\n",
        "        return task_data, feedback_result.content.strip()\n",
        "    return {}, \"\"\n",
        "\n",
        "def download_results():\n",
        "    df = pd.DataFrame(interview_data)\n",
        "    filename = f\"interview_results_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "    df.to_csv(filename, index=False)\n",
        "    return filename\n",
        "\n",
        "# -------------------- Gradio UI --------------------\n",
        "with gr.Blocks(theme='Respair/Shiki@1.2.1') as app:\n",
        "    gr.Markdown(\"\"\"\n",
        "        # 🎤 AI Interviewer\n",
        "        Upload your CV, paste a link, add job requirements, and begin an interactive mock interview with voice and text.\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        cv_file = gr.File(label=\"📄 Upload CV\")\n",
        "        cv_url = gr.Textbox(label=\"🌐 Or paste CV Link\")\n",
        "\n",
        "    job_input = gr.Textbox(label=\"🏢 Job Requirements or URL\")\n",
        "    start_btn = gr.Button(\"🚀 Start Interview\")\n",
        "\n",
        "    question_output = gr.Textbox(label=\"🧠 Interview Question\", lines=2)\n",
        "    mic_input = gr.Audio(type=\"filepath\", label=\"🎙️ Speak your answer\")\n",
        "    text_input = gr.Textbox(label=\"✍️ Or type your answer\")\n",
        "    submit_btn = gr.Button(\"✅ Submit Answer\")\n",
        "    next_btn = gr.Button(\"⏭️ Next Question\")\n",
        "\n",
        "    score_output = gr.Textbox(label=\"📊 Score & Feedback\")\n",
        "    task_output = gr.Textbox(label=\"🧪 Extra Task (if any)\")\n",
        "    feedback_output = gr.Textbox(label=\"🧾 Final Feedback\")\n",
        "    download_btn = gr.Button(\"📥 Download Full Interview Report\")\n",
        "    download_file = gr.File()\n",
        "    error_box = gr.Textbox(label=\"🚨 Error Log (if any)\", lines=2, interactive=False)\n",
        "    state = gr.State({})\n",
        "\n",
        "    def start(cv_file, cv_url, job_input):\n",
        "        try:\n",
        "            cv_text = load_cv(cv_file, cv_url)\n",
        "            job_data = extract_job_info(job_input)\n",
        "            questions = get_random_questions(8)\n",
        "            new_state = {\n",
        "                \"cv_text\": cv_text,\n",
        "                \"job_data\": job_data,\n",
        "                \"questions\": questions,\n",
        "                \"current\": 0,\n",
        "                \"answers\": []\n",
        "            }\n",
        "            return questions[0] if questions else \"No questions available.\", new_state, \"\"\n",
        "        except Exception as e:\n",
        "            return \"❌ Error occurred while starting interview.\", {}, str(e)\n",
        "\n",
        "    def submit_answer(audio_path, text, state):\n",
        "        try:\n",
        "            question = state[\"questions\"][state[\"current\"]]\n",
        "            if not text and audio_path:\n",
        "                text = transcribe_audio(audio_path)\n",
        "\n",
        "            answer = text or \"(No valid response)\"\n",
        "            result = ask_next_question(question, answer)\n",
        "            score = result[\"score\"]\n",
        "            feedback = result[\"feedback\"]\n",
        "\n",
        "            interview_data.append({\n",
        "                \"question\": question,\n",
        "                \"answer\": answer,\n",
        "                \"score\": score,\n",
        "                \"feedback\": feedback\n",
        "            })\n",
        "\n",
        "            state[\"answers\"].append((question, answer, score))\n",
        "\n",
        "            avg_score = sum(s for _, _, s in state[\"answers\"]) / len(state[\"answers\"])\n",
        "            task, final_feedback = generate_follow_up(avg_score, state[\"job_data\"], state[\"cv_text\"])\n",
        "\n",
        "            return f\"Score: {score}\\nFeedback: {feedback}\", task.get(\"instructions\", \"\"), final_feedback, state, \"\"\n",
        "        except Exception as e:\n",
        "            return \"\", \"\", \"\", state, str(e)\n",
        "\n",
        "    def go_to_next_question(state):\n",
        "        try:\n",
        "            state[\"current\"] += 1\n",
        "            if state[\"current\"] < len(state[\"questions\"]):\n",
        "                return state[\"questions\"][state[\"current\"]], state, \"\"\n",
        "            else:\n",
        "                return \"✅ Interview Complete\", state, \"\"\n",
        "        except Exception as e:\n",
        "            return \"❌ Error moving to next question\", state, str(e)\n",
        "\n",
        "    def download():\n",
        "        try:\n",
        "            return download_results()\n",
        "        except Exception as e:\n",
        "            return str(e)\n",
        "\n",
        "    start_btn.click(fn=start, inputs=[cv_file, cv_url, job_input], outputs=[question_output, state, error_box])\n",
        "    submit_btn.click(fn=submit_answer, inputs=[mic_input, text_input, state], outputs=[score_output, task_output, feedback_output, state, error_box])\n",
        "    next_btn.click(fn=go_to_next_question, inputs=[state], outputs=[question_output, state, error_box])\n",
        "    download_btn.click(fn=download, outputs=download_file)\n",
        "\n",
        "app.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "d5r1Ft3KSRbl",
        "outputId": "93ff0961-315d-4e7f-9d5a-b4b0d447815c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://4867b73982fd3886c9.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4867b73982fd3886c9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    }
  ]
}